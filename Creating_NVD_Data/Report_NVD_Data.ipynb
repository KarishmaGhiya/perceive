{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    NVD DATA: This notebook explains the process of parsing available NVD data from XML format to CSV, merging them to one master dataset, creating visulaization to gain initial insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing XML to CSV:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We require few fields to be extraxted for our initial analysis, thus we will parse only those tags. There are files from 2002 to 2017 available on the NVD website(https://nvd.nist.gov/download.cfm). The code below only shows the procedure for the final year but the File names have to changed according to the file we are currently reading. This process has to be iterated. (Repeat this for all files individually from 2002 - 2017, including the file named recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parsing using ElelmentTree\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Find root node\n",
    "CVE_tree = ET.parse(\"nvdcve-2.0-2017.xml\")\n",
    "CVE_root= CVE_tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element '{http://scap.nist.gov/schema/feed/vulnerability/2.0}nvd' at 0x49f1048>\n"
     ]
    }
   ],
   "source": [
    "print (CVE_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create new CSV file to write the extracted fields\n",
    "f = open('CVE_2017.csv', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extracting attributes and tags\n",
    "CVE_count = 0;\n",
    "CVE_listOfId = [];\n",
    "for entry in CVE_root:\n",
    "    cve_id = \"\";\n",
    "    cwe_id = \"\";\n",
    "    modified_date = \"\";\n",
    "    cvss = \"\";\n",
    "    for child in entry:\n",
    "        \n",
    "        #print (child.tag) #Print Child.tag will help you code further to identify child nodes\n",
    "        \n",
    "        if (child.tag == '{http://scap.nist.gov/schema/vulnerability/0.4}cve-id'):\n",
    "            cve_id = child.text;\n",
    "        if (child.tag == '{http://scap.nist.gov/schema/vulnerability/0.4}cwe'):\n",
    "            cwe_id = child.attrib['id'];\n",
    "        if (child.tag == '{http://scap.nist.gov/schema/vulnerability/0.4}cvss'):\n",
    "            cvss = child.text;\n",
    "        if (child.tag == '{http://scap.nist.gov/schema/vulnerability/0.4}published-datetime'):\n",
    "            modified_date = child.text;\n",
    "            \n",
    "    #vuln = cve_id+\",\"+cwe_id+\",\"+modified_date+\",\"+cvss+\"\\n\";\n",
    "    vuln = '{o1},{o2},{o3},{o1}\\n'.format(o1=cve_id,o2=cwe_id,o3=modified_date,o4=cvss);\n",
    "    f.write(vuln);\n",
    "    CVE_count = CVE_count +1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484\n"
     ]
    }
   ],
   "source": [
    "#This is to ensure that the file has been written into\n",
    "print (CVE_count)\n",
    "f.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have multiple individual CSV files corresponding to each year, we have to merge the files to yield one usable master database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fout=open(\"Merged_2002-17.csv\",\"a\")\n",
    "# first file:\n",
    "for line in open(\"CVE_2002.csv\"):\n",
    "    fout.write(line)\n",
    "# now the rest:    \n",
    "for num in range(2003,2017):\n",
    "    f = open(\"CVE_\"+str(num)+\".csv\")\n",
    "    #f.next() # skip the header\n",
    "    for line in f:\n",
    "         fout.write(line)\n",
    "    f.close() # not really needed\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gain insights we need to know the number of vulnerabilites that have a valid CWE ID. We therefore create a new dataset that will make this visualization easy to produce.\n",
    "The new dataset will contain the year, month and percentage ratio of number of CWE ID to CVE ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using panda \n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Open merged file to calculate values\n",
    "File= pd.read_csv(\"Merged_2002-17.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#using hashmap, we will store a key value pair of every month and year combination\n",
    "with open('Merged_2002-17.csv','r') as f:\n",
    "    r = csv.reader(f, delimiter=',')\n",
    "    cve_count = {};\n",
    "    cwe_count = {};\n",
    "    index = 0;\n",
    "    for row in r:\n",
    "        if(index!=0):\n",
    "            year = row[2];\n",
    "            month = row[3];\n",
    "            CWE = row[1];\n",
    "            CVE = row[0];\n",
    "            timestamp = row[4];\n",
    "            key = \"01/\"+month+\"/\"+year;\n",
    "    #checking if that combination exists and incrementing count of CVE ID and CWE ID\n",
    "            if key in cve_count:\n",
    "                curr = cve_count[key];\n",
    "                cve_count[key] = curr+1;\n",
    "            else:\n",
    "                cve_count[key] = 1;\n",
    "\n",
    "            if CWE != \"0\":\n",
    "                if key in cwe_count:\n",
    "                    curr = cwe_count[key];\n",
    "                    cwe_count[key] = curr+1;\n",
    "                else:\n",
    "                    cwe_count[key] = 1;\n",
    "        index = index+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a hashmap for the ratio values\n",
    "ratioMap = {};\n",
    "for k,v in cve_count.iteritems():\n",
    "    cve_c = v;\n",
    "    cwe_c = 0;\n",
    "    if k in cwe_count:\n",
    "        \n",
    "        cwe_c = cwe_count[k];\n",
    "    ratioMap[k] = round(100 * float(cwe_c)/float(cve_c),2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#writing hashmap values to a file\n",
    "f = open('ratio_v1.csv', 'w')\n",
    "Header = \"Date,Percentage\\n\";\n",
    "f.write(Header);\n",
    "for k,v in ratioMap.iteritems():\n",
    "    \n",
    "    outline = \"{o1},{o3}\\n\".format(o1=k, o3=v);\n",
    "    #print outline;\n",
    "    f.write(outline);\n",
    "f.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Visualization using Bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.charts import TimeSeries, show, output_file, vplot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from dateutil import parser\n",
    "from bokeh.layouts import column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Open file for visualization\n",
    "Plot_File= pd.read_csv(\"ratio_v1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date = Plot_File['Date'];\n",
    "per = Plot_File['Percentage'];   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#at this point the csv doesn't take the date column to be a date but a string\n",
    "i=0;\n",
    "dt = [];\n",
    "for d in date:\n",
    "    dt.append(d)\n",
    "    \n",
    "    try:\n",
    "        dt[i] = parser.parse(date[i]);\n",
    "    except ValueError:\n",
    "        print date[i];\n",
    "    #No exceptions? We can proceed\n",
    "    i+=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a dictionary\n",
    "data = dict(\n",
    "    Date=dt,\n",
    "    PERCENTAGE=per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a timeseries graph with points\n",
    "tspoint = TimeSeries(data,\n",
    "    x='Date', y=['PERCENTAGE'],\n",
    "    color=['PERCENTAGE'], dash=['PERCENTAGE'], builder_type='point',\n",
    "    title=\"Timeseries\", ylabel='Stock Prices', legend=True)\n",
    "#create a timeseries graph with a line\n",
    "tsline = TimeSeries(data,\n",
    "    x='Date', y=['PERCENTAGE'],\n",
    "    color=['PERCENTAGE'], dash=['PERCENTAGE'], builder_type='line',\n",
    "    title=\"Timeseries\", ylabel='Stock Prices', legend=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#saves figures in an html file\n",
    "output_file(\"timeseries_final.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#opens visualization\n",
    "show(column(tsline,tspoint))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
